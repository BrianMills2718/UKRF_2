#!/usr/bin/env python3
"""
Comprehensive Neo4j Error Message Verification Test

This test verifies that all Neo4j error messages across the GraphRAG system 
are clear, helpful, and provide actionable feedback to users.

According to CLAUDE.md guidelines:
- Error messages should be clear and helpful
- Users should know exactly why operations failed
- No mock data should be returned when Neo4j is unavailable
- All failures should be explicit rather than silent
"""

import sys
import traceback
from typing import Dict, List, Any

def test_neo4j_error_scenarios():
    """Test various Neo4j connection failure scenarios."""
    
    results = {
        "scenarios_tested": 0,
        "scenarios_passed": 0,
        "error_message_quality": {},
        "issues_found": [],
        "all_tests": []
    }
    
    print("üß™ Testing Neo4j Error Message Quality")
    print("=" * 60)
    
    # Scenario 1: Phase 1 Tools with Invalid Connection
    print("\nüìã Phase 1 Tools - Invalid Connection Tests")
    print("-" * 40)
    
    # Test T31 Entity Builder
    test_result = test_entity_builder_errors()
    results["all_tests"].append(test_result)
    results["scenarios_tested"] += 1
    if test_result["passed"]:
        results["scenarios_passed"] += 1
    print_test_result("T31 Entity Builder", test_result)
    
    # Test T34 Edge Builder  
    test_result = test_edge_builder_errors()
    results["all_tests"].append(test_result)
    results["scenarios_tested"] += 1
    if test_result["passed"]:
        results["scenarios_passed"] += 1
    print_test_result("T34 Edge Builder", test_result)
    
    # Test T49 Multi-hop Query
    test_result = test_multihop_query_errors()
    results["all_tests"].append(test_result)
    results["scenarios_tested"] += 1
    if test_result["passed"]:
        results["scenarios_passed"] += 1
    print_test_result("T49 Multi-hop Query", test_result)
    
    # Test T68 PageRank Calculator
    test_result = test_pagerank_errors()
    results["all_tests"].append(test_result)
    results["scenarios_tested"] += 1
    if test_result["passed"]:
        results["scenarios_passed"] += 1
    print_test_result("T68 PageRank Calculator", test_result)
    
    # Scenario 2: Service Manager
    print("\nüìã Service Manager - Connection Tests")
    print("-" * 40)
    
    test_result = test_service_manager_errors()
    results["all_tests"].append(test_result)
    results["scenarios_tested"] += 1
    if test_result["passed"]:
        results["scenarios_passed"] += 1
    print_test_result("Service Manager", test_result)
    
    # Scenario 3: Phase 2 Tools
    print("\nüìã Phase 2 Tools - Invalid Connection Tests")
    print("-" * 40)
    
    test_result = test_phase2_ontology_builder_errors()
    results["all_tests"].append(test_result)
    results["scenarios_tested"] += 1
    if test_result["passed"]:
        results["scenarios_passed"] += 1
    print_test_result("Phase 2 Ontology Builder", test_result)
    
    # Analyze error message quality
    print("\nüìä Error Message Quality Analysis")
    print("-" * 40)
    
    for test in results["all_tests"]:
        if test["error_message"]:
            quality_score = analyze_error_message_quality(test["error_message"])
            results["error_message_quality"][test["component"]] = quality_score
            
            print(f"‚Ä¢ {test['component']}: {quality_score['score']}/10")
            if quality_score['score'] < 7:
                results["issues_found"].append({
                    "component": test["component"],
                    "issue": "Poor error message quality",
                    "score": quality_score['score'],
                    "message": test["error_message"],
                    "suggestions": quality_score['suggestions']
                })
    
    # Summary
    print("\nüéØ Summary")
    print("-" * 40)
    pass_rate = (results["scenarios_passed"] / results["scenarios_tested"]) * 100
    print(f"Tests Passed: {results['scenarios_passed']}/{results['scenarios_tested']} ({pass_rate:.1f}%)")
    
    if results["issues_found"]:
        print(f"\n‚ùå Issues Found: {len(results['issues_found'])}")
        for issue in results["issues_found"]:
            print(f"  ‚Ä¢ {issue['component']}: {issue['issue']} (Score: {issue['score']}/10)")
            print(f"    Message: '{issue['message']}'")
            for suggestion in issue['suggestions']:
                print(f"    üí° {suggestion}")
    else:
        print("‚úÖ All error messages meet quality standards!")
    
    # Overall grade
    avg_quality = sum(q['score'] for q in results["error_message_quality"].values()) / len(results["error_message_quality"]) if results["error_message_quality"] else 0
    print(f"\nüìà Overall Error Message Quality: {avg_quality:.1f}/10")
    
    if avg_quality >= 8:
        print("üåü EXCELLENT - Error messages are clear and helpful")
    elif avg_quality >= 6:
        print("‚úÖ GOOD - Error messages are adequate with minor improvements needed")
    elif avg_quality >= 4:
        print("‚ö†Ô∏è FAIR - Error messages need improvement")
    else:
        print("‚ùå POOR - Error messages need significant improvement")
    
    return results


def test_entity_builder_errors():
    """Test T31 Entity Builder error handling."""
    try:
        from src.tools.phase1.t31_entity_builder import EntityBuilder
        from src.core.service_manager import ServiceManager
        
        sm = ServiceManager()
        builder = EntityBuilder(
            sm.identity_service,
            sm.provenance_service,
            sm.quality_service,
            neo4j_uri='bolt://invalid-host:7687',
            neo4j_user='neo4j',
            neo4j_password='wrong_password'
        )
        
        result = builder.build_entities(
            mentions=[{'mention_id': 'test', 'entity_id': 'test', 'surface_form': 'test'}],
            source_refs=['test']
        )
        
        return {
            "component": "T31 Entity Builder",
            "passed": result["status"] == "error" and "Neo4j connection not available" in result.get("error", ""),
            "error_message": result.get("error", ""),
            "status": result["status"],
            "details": "Should return clear error when Neo4j unavailable"
        }
        
    except Exception as e:
        return {
            "component": "T31 Entity Builder",
            "passed": False,
            "error_message": f"Test failed with exception: {str(e)}",
            "status": "exception",
            "details": "Test setup failed"
        }


def test_edge_builder_errors():
    """Test T34 Edge Builder error handling."""
    try:
        from src.tools.phase1.t34_edge_builder import EdgeBuilder
        from src.core.service_manager import ServiceManager
        
        sm = ServiceManager()
        builder = EdgeBuilder(
            sm.identity_service,
            sm.provenance_service,
            sm.quality_service,
            neo4j_uri='bolt://invalid-host:7687',
            neo4j_user='neo4j',
            neo4j_password='wrong_password'
        )
        
        result = builder.build_edges(
            relationships=[{
                'relationship_id': 'test', 
                'subject_entity_id': 'test', 
                'object_entity_id': 'test', 
                'relationship_type': 'test', 
                'confidence': 0.5
            }],
            source_refs=['test']
        )
        
        return {
            "component": "T34 Edge Builder",
            "passed": result["status"] == "error" and "Neo4j connection not available" in result.get("error", ""),
            "error_message": result.get("error", ""),
            "status": result["status"],
            "details": "Should return clear error when Neo4j unavailable"
        }
        
    except Exception as e:
        return {
            "component": "T34 Edge Builder",
            "passed": False,
            "error_message": f"Test failed with exception: {str(e)}",
            "status": "exception",
            "details": "Test setup failed"
        }


def test_multihop_query_errors():
    """Test T49 Multi-hop Query error handling."""
    try:
        from src.tools.phase1.t49_multihop_query import MultiHopQuery
        from src.core.service_manager import ServiceManager
        
        sm = ServiceManager()
        query_tool = MultiHopQuery(
            sm.identity_service,
            sm.provenance_service,
            sm.quality_service,
            neo4j_uri='bolt://invalid-host:7687',
            neo4j_user='neo4j',
            neo4j_password='wrong_password'
        )
        
        result = query_tool.query_graph('What is the capital of France?')
        
        return {
            "component": "T49 Multi-hop Query",
            "passed": result["status"] == "error" and "Neo4j connection not available" in result.get("error", ""),
            "error_message": result.get("error", ""),
            "status": result["status"],
            "details": "Should return clear error when Neo4j unavailable"
        }
        
    except Exception as e:
        return {
            "component": "T49 Multi-hop Query",
            "passed": False,
            "error_message": f"Test failed with exception: {str(e)}",
            "status": "exception",
            "details": "Test setup failed"
        }


def test_pagerank_errors():
    """Test T68 PageRank Calculator error handling."""
    try:
        from src.tools.phase1.t68_pagerank import PageRankCalculator
        from src.core.service_manager import ServiceManager
        
        sm = ServiceManager()
        pagerank = PageRankCalculator(
            sm.identity_service,
            sm.provenance_service,
            sm.quality_service,
            neo4j_uri='bolt://invalid-host:7687',
            neo4j_user='neo4j',
            neo4j_password='wrong_password'
        )
        
        result = pagerank.calculate_pagerank()
        
        return {
            "component": "T68 PageRank Calculator",
            "passed": result["status"] == "error" and "Neo4j connection not available" in result.get("error", ""),
            "error_message": result.get("error", ""),
            "status": result["status"],
            "details": "Should return clear error when Neo4j unavailable"
        }
        
    except Exception as e:
        return {
            "component": "T68 PageRank Calculator",
            "passed": False,
            "error_message": f"Test failed with exception: {str(e)}",
            "status": "exception",
            "details": "Test setup failed"
        }


def test_service_manager_errors():
    """Test Service Manager Neo4j error handling."""
    try:
        from src.core.service_manager import ServiceManager
        
        sm = ServiceManager()
        # Test invalid connection
        driver = sm.get_neo4j_driver(
            uri='bolt://invalid-host:7687',
            user='neo4j',
            password='wrong_password'
        )
        
        return {
            "component": "Service Manager",
            "passed": driver is None,  # Should return None on failure
            "error_message": "Connection failed gracefully with warning message",
            "status": "handled",
            "details": "Should return None and print warning when connection fails"
        }
        
    except Exception as e:
        return {
            "component": "Service Manager",
            "passed": False,
            "error_message": f"Test failed with exception: {str(e)}",
            "status": "exception",
            "details": "Test setup failed"
        }


def test_phase2_ontology_builder_errors():
    """Test Phase 2 Ontology Builder error handling."""
    try:
        from src.tools.phase2.t31_ontology_graph_builder import OntologyAwareGraphBuilder
        
        # This should raise an exception since it doesn't gracefully handle connection failures
        try:
            builder = OntologyAwareGraphBuilder(
                neo4j_uri='bolt://invalid-host:7687',
                neo4j_user='neo4j',
                neo4j_password='wrong_password'
            )
            return {
                "component": "Phase 2 Ontology Builder",
                "passed": False,
                "error_message": "Should have failed but didn't",
                "status": "unexpected_success",
                "details": "Constructor should fail with invalid connection"
            }
        except Exception as e:
            return {
                "component": "Phase 2 Ontology Builder",
                "passed": "Cannot resolve address" in str(e) or "connection failed" in str(e).lower(),
                "error_message": str(e),
                "status": "exception_as_expected",
                "details": "Constructor properly fails with invalid connection"
            }
        
    except ImportError as e:
        return {
            "component": "Phase 2 Ontology Builder",
            "passed": True,  # Not available, so can't test, but that's OK
            "error_message": f"Component not available: {str(e)}",
            "status": "not_available",
            "details": "Phase 2 component not found - may not be implemented"
        }
    except Exception as e:
        return {
            "component": "Phase 2 Ontology Builder",
            "passed": False,
            "error_message": f"Test failed with exception: {str(e)}",
            "status": "test_exception",
            "details": "Test setup failed"
        }


def analyze_error_message_quality(message: str) -> Dict[str, Any]:
    """Analyze the quality of an error message."""
    if not message:
        return {"score": 0, "suggestions": ["Error message is empty"]}
    
    score = 0
    suggestions = []
    
    # Check if message is clear and descriptive (2 points)
    if len(message) > 20 and any(word in message.lower() for word in ['connection', 'neo4j', 'database', 'unavailable']):
        score += 2
    else:
        suggestions.append("Make message more descriptive about the specific issue")
    
    # Check if message explains what failed (2 points)
    if any(word in message.lower() for word in ['cannot', 'failed', 'not available', 'unavailable']):
        score += 2
    else:
        suggestions.append("Clearly state what operation failed")
    
    # Check if message mentions the component (1 point)
    if any(word in message.lower() for word in ['neo4j', 'database', 'graph', 'connection']):
        score += 1
    else:
        suggestions.append("Specify which component/service failed")
    
    # Check for actionable information (2 points)
    if any(phrase in message.lower() for phrase in ['check', 'verify', 'ensure', 'configure']):
        score += 2
    elif 'connection' in message.lower():
        score += 1  # Partial credit for mentioning connection
        suggestions.append("Provide actionable steps to resolve the issue")
    else:
        suggestions.append("Include actionable guidance for users")
    
    # Check for professional tone (1 point)
    if not any(word in message.lower() for word in ['error', 'failed', 'problem']) or 'cannot' in message.lower():
        score += 1
    else:
        suggestions.append("Use professional, user-friendly language")
    
    # Check for specificity vs genericity (2 points)
    if any(specific in message.lower() for specific in ['neo4j connection', 'graph database', 'build entity graph', 'query graph']):
        score += 2
    else:
        suggestions.append("Be more specific about what functionality is affected")
    
    return {"score": score, "suggestions": suggestions}


def print_test_result(component: str, result: Dict[str, Any]):
    """Print a formatted test result."""
    status_icon = "‚úÖ" if result["passed"] else "‚ùå"
    print(f"{status_icon} {component}: {result['status']}")
    if result["error_message"]:
        print(f"   Message: '{result['error_message']}'")
    if not result["passed"] and result.get("details"):
        print(f"   Details: {result['details']}")


if __name__ == "__main__":
    try:
        results = test_neo4j_error_scenarios()
        
        # Exit with appropriate code
        if results["scenarios_passed"] == results["scenarios_tested"] and not results["issues_found"]:
            sys.exit(0)  # All tests passed
        else:
            sys.exit(1)  # Some tests failed or issues found
            
    except Exception as e:
        print(f"\nüí• Test framework failed: {e}")
        traceback.print_exc()
        sys.exit(2)  # Test framework error